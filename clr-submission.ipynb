{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026874,
     "end_time": "2021-07-31T10:55:57.637583",
     "exception": false,
     "start_time": "2021-07-31T10:55:57.610709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook uses below given notebooks to make predictions.\n",
    "\n",
    "1. Pretrain Roberta Model: https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n",
    "2. Finetune Roberta Model: https://www.kaggle.com/maunish/clrp-pytorch-roberta-finetune\n",
    "3. Inference Notebook: https://www.kaggle.com/maunish/clrp-pytorch-roberta-inference\n",
    "4. Roberta + SVM: this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-31T10:55:57.706657Z",
     "iopub.status.busy": "2021-07-31T10:55:57.706058Z",
     "iopub.status.idle": "2021-07-31T10:56:07.956653Z",
     "shell.execute_reply": "2021-07-31T10:56:07.956086Z",
     "shell.execute_reply.started": "2021-07-31T10:19:56.180288Z"
    },
    "papermill": {
     "duration": 10.294631,
     "end_time": "2021-07-31T10:56:07.956829",
     "exception": false,
     "start_time": "2021-07-31T10:55:57.662198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (AutoModel, AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "y_ = Fore.YELLOW\n",
    "r_ = Fore.RED\n",
    "g_ = Fore.GREEN\n",
    "b_ = Fore.BLUE\n",
    "m_ = Fore.MAGENTA\n",
    "c_ = Fore.CYAN\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:56:08.010833Z",
     "iopub.status.busy": "2021-07-31T10:56:08.009594Z",
     "iopub.status.idle": "2021-07-31T10:56:08.011933Z",
     "shell.execute_reply": "2021-07-31T10:56:08.012303Z",
     "shell.execute_reply.started": "2021-07-31T10:20:13.774628Z"
    },
    "papermill": {
     "duration": 0.031192,
     "end_time": "2021-07-31T10:56:08.012429",
     "exception": false,
     "start_time": "2021-07-31T10:56:07.981237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Softmax, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:56:08.082425Z",
     "iopub.status.busy": "2021-07-31T10:56:08.065603Z",
     "iopub.status.idle": "2021-07-31T10:57:02.533415Z",
     "shell.execute_reply": "2021-07-31T10:57:02.532365Z",
     "shell.execute_reply.started": "2021-07-31T10:20:16.832770Z"
    },
    "papermill": {
     "duration": 54.497291,
     "end_time": "2021-07-31T10:57:02.533581",
     "exception": false,
     "start_time": "2021-07-31T10:56:08.036290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ../input/nlp-packages/nltk-3.6.2-py3-none-any.whl\n",
    "!pip install ../input/nlp-packages/pyphen-0.11.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:57:02.589075Z",
     "iopub.status.busy": "2021-07-31T10:57:02.588216Z",
     "iopub.status.idle": "2021-07-31T10:57:11.650428Z",
     "shell.execute_reply": "2021-07-31T10:57:11.649516Z",
     "shell.execute_reply.started": "2021-07-31T10:21:57.037406Z"
    },
    "papermill": {
     "duration": 9.09213,
     "end_time": "2021-07-31T10:57:11.650577",
     "exception": false,
     "start_time": "2021-07-31T10:57:02.558447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import plotly.express as px\n",
    "#import matplotlib as plt\n",
    "import spacy\n",
    "#import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import SyllableTokenizer\n",
    "from nltk import word_tokenize\n",
    "import pyphen\n",
    "import itertools\n",
    "#from g2p_en import G2p\n",
    "#from wordfreq import zipf_frequency\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:57:11.704460Z",
     "iopub.status.busy": "2021-07-31T10:57:11.703959Z",
     "iopub.status.idle": "2021-07-31T10:57:11.792538Z",
     "shell.execute_reply": "2021-07-31T10:57:11.792071Z",
     "shell.execute_reply.started": "2021-07-31T10:22:13.256015Z"
    },
    "papermill": {
     "duration": 0.116445,
     "end_time": "2021-07-31T10:57:11.792651",
     "exception": false,
     "start_time": "2021-07-31T10:57:11.676206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\n",
    "sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:57:11.850533Z",
     "iopub.status.busy": "2021-07-31T10:57:11.849850Z",
     "iopub.status.idle": "2021-07-31T10:57:11.852527Z",
     "shell.execute_reply": "2021-07-31T10:57:11.852144Z",
     "shell.execute_reply.started": "2021-07-31T10:22:16.101288Z"
    },
    "papermill": {
     "duration": 0.035697,
     "end_time": "2021-07-31T10:57:11.852638",
     "exception": false,
     "start_time": "2021-07-31T10:57:11.816941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.rename(columns={'excerpt':'Text'})\n",
    "df_test = df_test.rename(columns={'excerpt':'Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:57:12.190169Z",
     "iopub.status.busy": "2021-07-31T10:57:11.923679Z",
     "iopub.status.idle": "2021-07-31T10:57:12.192060Z",
     "shell.execute_reply": "2021-07-31T10:57:12.192422Z",
     "shell.execute_reply.started": "2021-07-31T10:22:21.898398Z"
    },
    "papermill": {
     "duration": 0.31609,
     "end_time": "2021-07-31T10:57:12.192567",
     "exception": false,
     "start_time": "2021-07-31T10:57:11.876477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_feature(df, func, features, on='Text', args=()):\n",
    "    old_cols = list(df.columns)\n",
    "    if type(features) != list : features = [features]\n",
    "    if not set(old_cols).isdisjoint(set(features)):\n",
    "        print('Overwriting existing features')\n",
    "    df = df.drop(features, axis=1, errors='ignore')\n",
    "    old_cols = list(df.columns)\n",
    "    df1 = df[on].apply(func, args=tuple(args))\n",
    "    df = pd.concat([df, df1], axis=1)\n",
    "    df.columns = old_cols + features\n",
    "    #print(df[[on] + features].head(3))\n",
    "    print(features)\n",
    "    return df\n",
    "\n",
    "def get_sent_list_spacy(doc):\n",
    "    return list(doc.sents)\n",
    "\n",
    "def get_sent_count(sent_list):\n",
    "    return len(sent_list)\n",
    "\n",
    "def get_token_list_by_sent(sent):\n",
    "    return [[i for i in j if str(i).isalnum()] for j in sent]\n",
    "\n",
    "def get_word_list_by_sent(token_list):\n",
    "    return [[j.text for j in i] for i in token_list]\n",
    "\n",
    "def get_token_list_full(token_list):\n",
    "    return [i for j in token_list for i in j]\n",
    "\n",
    "def get_word_list_full(token_list):\n",
    "    return [i.text for i in token_list]\n",
    "\n",
    "def get_sent_len(token_list):\n",
    "    return [len(i) for i in token_list]\n",
    "\n",
    "def get_word_list_nltk(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "def get_word_len(token_list):\n",
    "    return [len(i) for i in token_list]\n",
    "\n",
    "def get_pos_tag_spacy(token_list_sent):\n",
    "    return [[i.pos_ for i in j] for j in token_list_sent]\n",
    "\n",
    "def get_dep_tag_spacy(token_list_sent):\n",
    "    return [[i.dep_ for i in j] for j in token_list_sent]\n",
    "\n",
    "def get_verb_phrase_count(spacy_sent):\n",
    "    '''input : spacy doc\n",
    "       output: number of VP in text'''\n",
    "    pattern = [{'POS': 'VERB', 'OP': '?'},\n",
    "               {'POS': 'ADV', 'OP': '*'},\n",
    "               {'POS': 'AUX', 'OP': '*'},\n",
    "               {'POS': 'VERB', 'OP': '+'}]\n",
    "    count_list = []\n",
    "    for sent in spacy_sent:\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        matcher.add(\"Verb phrase\", [pattern])\n",
    "        matches = matcher(sent)\n",
    "        spans = [sent[start:end] for _, start, end in matches]\n",
    "        count_list.append(len(filter_spans(spans)))\n",
    "\n",
    "    return count_list\n",
    "\n",
    "def get_noun_phrase_count(spacy_sent):\n",
    "    '''input : spacy doc\n",
    "       output: number of NP in text'''\n",
    "    count_list = []\n",
    "    for sent in spacy_sent:\n",
    "        NP_list = []\n",
    "        for chunk in sent.noun_chunks:\n",
    "            NP_list.append(chunk)\n",
    "        count_list.append(len(NP_list))\n",
    "    return count_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:57:12.260892Z",
     "iopub.status.busy": "2021-07-31T10:57:12.259624Z",
     "iopub.status.idle": "2021-07-31T10:57:12.262373Z",
     "shell.execute_reply": "2021-07-31T10:57:12.261983Z",
     "shell.execute_reply.started": "2021-07-31T10:22:38.925171Z"
    },
    "papermill": {
     "duration": 0.045689,
     "end_time": "2021-07-31T10:57:12.262478",
     "exception": false,
     "start_time": "2021-07-31T10:57:12.216789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_features(data):\n",
    "    data = add_feature(data, nlp, 'Spacy_Doc')\n",
    "    data = add_feature(data, get_sent_list_spacy, 'Spacy_Sents', on='Spacy_Doc')\n",
    "    data = add_feature(data, get_sent_count, 'Num_Sents', on='Spacy_Sents')\n",
    "    data = add_feature(data, get_token_list_by_sent, 'Token_list_sent', on='Spacy_Sents')\n",
    "    data = add_feature(data, get_word_list_by_sent, 'Word_list_sent', on='Token_list_sent')\n",
    "    data = add_feature(data, get_token_list_full, 'Token_list', on='Token_list_sent')\n",
    "    data = add_feature(data, get_word_list_full, 'Word_list_full', on='Token_list')\n",
    "    data = add_feature(data, get_sent_len, 'Sent_len', on='Token_list_sent')\n",
    "    data = add_feature(data, get_word_list_nltk, 'Word_list', on='Text')\n",
    "    data = add_feature(data, len, 'Num_Words', on='Token_list')\n",
    "    data = add_feature(data, len, 'Num_Chars', on='Text')\n",
    "    data = add_feature(data, get_word_len, 'Word_len', on='Token_list')\n",
    "##     data = add_feature(data, get_phone_count, 'Phone_count', on='Token_list')\n",
    "##     data = add_feature(data, get_phone_list, 'Phone_list', on='Token_list')\n",
    "    data = add_feature(data, get_pos_tag_nltk, 'Pos_tag_nltk', on='Word_list_sent')\n",
    "    data = add_feature(data, get_pos_tag_spacy, 'Pos_tag_spacy', on='Token_list_sent')\n",
    "    data = add_feature(data, get_dep_tag_spacy, 'Dep_tag_spacy', on='Token_list_sent')\n",
    "##    data = add_feature(data, get_commonality_of_word, 'Commonality_list', on='Token_list')\n",
    "    data = add_feature(data, get_stop_word_count, 'Stopwords_ratio', on='Token_list')\n",
    "    data = add_feature(data, get_unique_word_count, 'Unique_words_ratio', on='Token_list')\n",
    "    data = add_feature(data, get_pos_count, 'POS_counter', on='Pos_tag_spacy')\n",
    "    for i in (['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', \n",
    "               'NUM', 'PART', 'PRON', 'PROPN', 'SCONJ', 'VERB']):\n",
    "        data[i+'_ratio'] = data['POS_counter'].apply(lambda x:x[i])\n",
    "        data[i+'_ratio'] = data[i+'_ratio']*100/data['Num_Words']\n",
    "    data = add_feature(data, get_dep_count, 'DEP_counter', on='Dep_tag_spacy')\n",
    "    for i in (['ROOT', 'acl', 'acomp', 'advcl', 'advmod', 'agent', 'amod', 'appos', 'attr', 'aux', 'auxpass', 'case', 'cc', \n",
    "               'ccomp', 'compound', 'conj', 'csubj', 'csubjpass', 'dative', 'dep', 'det', 'dobj', 'expl', 'intj', 'mark', \n",
    "               'meta', 'neg', 'nmod', 'npadvmod', 'nsubj', 'nsubjpass', 'nummod', 'oprd', 'parataxis', 'pcomp', 'pobj', 'poss', \n",
    "               'preconj', 'predet', 'prep', 'prt', 'punct', 'quantmod', 'relcl', 'xcomp']):\n",
    "        data[i+'_ratio'] = data['DEP_counter'].apply(lambda x:x[i])\n",
    "        data[i+'_ratio'] = data[i+'_ratio']*100/data['Num_Words']\n",
    "    data['Content_Word_ratio'] = data['NOUN_ratio'] + data['VERB_ratio'] + data['ADJ_ratio'] + data['ADV_ratio']\n",
    "    data['Connectives_ratio'] = data['SCONJ_ratio'] + data['CCONJ_ratio']\n",
    "    data = add_feature(data, get_verb_phrase_count, 'Verb_phrase_count', on='Spacy_Sents')\n",
    "    data = add_feature(data, get_noun_phrase_count, 'Noun_phrase_count', on='Spacy_Sents')\n",
    " \n",
    "    \n",
    "    for i in ['Sent_len', 'Word_len', 'Syl_count_pyphen', 'Syl_count_nltk', \n",
    "              'Verb_phrase_count', 'Noun_phrase_count']:\n",
    "        df1 = pd.DataFrame(data[i].apply(lambda x:np.quantile(x, [0.10, 0.25, 0.50, 0.75, 0.90])).tolist(), \n",
    "                           columns=[i+'_Q1', i+'_Q2', i+'_Q3', i+'_Q4', i+'_Q5'])\n",
    "        data = pd.concat([data, df1], axis=1)\n",
    "        data[i+'_mean'] = data[i].apply(lambda x:np.mean(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:57:12.317755Z",
     "iopub.status.busy": "2021-07-31T10:57:12.317067Z",
     "iopub.status.idle": "2021-07-31T10:57:12.319442Z",
     "shell.execute_reply": "2021-07-31T10:57:12.319910Z",
     "shell.execute_reply.started": "2021-07-31T10:22:43.648197Z"
    },
    "papermill": {
     "duration": 0.03389,
     "end_time": "2021-07-31T10:57:12.320025",
     "exception": false,
     "start_time": "2021-07-31T10:57:12.286135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_keep = ['Num_Sents', 'Num_Words', 'Num_Chars', 'Stopwords_ratio', 'Unique_words_ratio', 'ADJ_ratio', 'ADP_ratio', 'ADV_ratio', 'AUX_ratio', \n",
    "    'CCONJ_ratio','DET_ratio', 'INTJ_ratio', 'NOUN_ratio', 'NUM_ratio', 'PART_ratio','PRON_ratio', 'PROPN_ratio', 'SCONJ_ratio', 'VERB_ratio',\n",
    "    'ROOT_ratio', 'acl_ratio', 'acomp_ratio', 'advcl_ratio', 'advmod_ratio', 'agent_ratio', 'amod_ratio', 'appos_ratio', 'attr_ratio', \n",
    "    'aux_ratio', 'auxpass_ratio', 'case_ratio', 'cc_ratio', 'ccomp_ratio', 'compound_ratio', 'conj_ratio', 'csubj_ratio', 'csubjpass_ratio',\n",
    "    'dative_ratio', 'dep_ratio', 'det_ratio', 'dobj_ratio', 'expl_ratio', 'intj_ratio', 'mark_ratio', 'meta_ratio', 'neg_ratio',\n",
    "    'nmod_ratio', 'npadvmod_ratio', 'nsubj_ratio', 'nsubjpass_ratio', 'nummod_ratio', 'oprd_ratio', 'parataxis_ratio', 'pcomp_ratio',\n",
    "    'pobj_ratio', 'poss_ratio', 'preconj_ratio', 'predet_ratio', 'prep_ratio', 'prt_ratio', 'punct_ratio', 'quantmod_ratio', 'relcl_ratio',\n",
    "    'xcomp_ratio', 'Content_Word_ratio', 'Connectives_ratio', 'Sent_len_Q1', 'Sent_len_Q2', 'Sent_len_Q3', 'Sent_len_Q4', 'Sent_len_Q5',\n",
    "    'Sent_len_mean', 'Word_len_Q1', 'Word_len_Q2', 'Word_len_Q3', 'Word_len_Q4', 'Word_len_Q5', 'Word_len_mean',\n",
    "    'Verb_phrase_count_Q1', 'Verb_phrase_count_Q2', 'Verb_phrase_count_Q3', 'Verb_phrase_count_Q4', 'Verb_phrase_count_Q5', 'Verb_phrase_count_mean',\n",
    "    'Noun_phrase_count_Q1', 'Noun_phrase_count_Q2', 'Noun_phrase_count_Q3', 'Noun_phrase_count_Q4', 'Noun_phrase_count_Q5', 'Noun_phrase_count_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:57:12.371173Z",
     "iopub.status.busy": "2021-07-31T10:57:12.370507Z",
     "iopub.status.idle": "2021-07-31T10:57:12.372850Z",
     "shell.execute_reply": "2021-07-31T10:57:12.373244Z",
     "shell.execute_reply.started": "2021-07-28T04:56:44.211656Z"
    },
    "papermill": {
     "duration": 0.029183,
     "end_time": "2021-07-31T10:57:12.373355",
     "exception": false,
     "start_time": "2021-07-31T10:57:12.344172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_train['weight'] = np.log(1 + (1/(df_train['standard_error'] + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T10:57:12.433270Z",
     "iopub.status.busy": "2021-07-31T10:57:12.430120Z",
     "iopub.status.idle": "2021-07-31T11:00:11.583514Z",
     "shell.execute_reply": "2021-07-31T11:00:11.582985Z",
     "shell.execute_reply.started": "2021-07-31T10:22:47.587588Z"
    },
    "papermill": {
     "duration": 179.186503,
     "end_time": "2021-07-31T11:00:11.583651",
     "exception": false,
     "start_time": "2021-07-31T10:57:12.397148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spacy_Doc']\n",
      "['Spacy_Sents']\n",
      "['Num_Sents']\n",
      "['Token_list_sent']\n",
      "['Word_list_sent']\n",
      "['Token_list']\n",
      "['Word_list_full']\n",
      "['Sent_len']\n",
      "['Word_list']\n",
      "['Num_Words']\n",
      "['Num_Chars']\n",
      "['Word_len']\n",
      "['Syl_count_pyphen']\n",
      "['Syl_count_nltk']\n",
      "['Syl_list_pyphen']\n",
      "['Syl_list_nltk']\n",
      "['Pos_tag_nltk']\n",
      "['Pos_tag_spacy']\n",
      "['Dep_tag_spacy']\n",
      "['Stopwords_ratio']\n",
      "['Unique_words_ratio']\n",
      "['POS_counter']\n",
      "['DEP_counter']\n",
      "['Verb_phrase_count']\n",
      "['Noun_phrase_count']\n",
      "['Adverb_phrase_count']\n",
      "['Prepositional_phrase_count']\n",
      "['Tree_max_depth_count']\n",
      "['Tree_length_count']\n"
     ]
    }
   ],
   "source": [
    "train_features = generate_features(df_train)\n",
    "train_features = train_features[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:11.692850Z",
     "iopub.status.busy": "2021-07-31T11:00:11.692048Z",
     "iopub.status.idle": "2021-07-31T11:00:12.862335Z",
     "shell.execute_reply": "2021-07-31T11:00:12.863053Z",
     "shell.execute_reply.started": "2021-07-31T10:27:45.342489Z"
    },
    "papermill": {
     "duration": 1.232628,
     "end_time": "2021-07-31T11:00:12.863252",
     "exception": false,
     "start_time": "2021-07-31T11:00:11.630624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spacy_Doc']\n",
      "['Spacy_Sents']\n",
      "['Num_Sents']\n",
      "['Token_list_sent']\n",
      "['Word_list_sent']\n",
      "['Token_list']\n",
      "['Word_list_full']\n",
      "['Sent_len']\n",
      "['Word_list']\n",
      "['Num_Words']\n",
      "['Num_Chars']\n",
      "['Word_len']\n",
      "['Syl_count_pyphen']\n",
      "['Syl_count_nltk']\n",
      "['Syl_list_pyphen']\n",
      "['Syl_list_nltk']\n",
      "['Pos_tag_nltk']\n",
      "['Pos_tag_spacy']\n",
      "['Dep_tag_spacy']\n",
      "['Stopwords_ratio']\n",
      "['Unique_words_ratio']\n",
      "['POS_counter']\n",
      "['DEP_counter']\n",
      "['Verb_phrase_count']\n",
      "['Noun_phrase_count']\n",
      "['Adverb_phrase_count']\n",
      "['Prepositional_phrase_count']\n",
      "['Tree_max_depth_count']\n",
      "['Tree_length_count']\n"
     ]
    }
   ],
   "source": [
    "test_features = generate_features(df_test)\n",
    "test_features = test_features[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:12.938845Z",
     "iopub.status.busy": "2021-07-31T11:00:12.936460Z",
     "iopub.status.idle": "2021-07-31T11:00:12.942668Z",
     "shell.execute_reply": "2021-07-31T11:00:12.943219Z",
     "shell.execute_reply.started": "2021-07-31T10:27:50.089744Z"
    },
    "papermill": {
     "duration": 0.044576,
     "end_time": "2021-07-31T11:00:12.943371",
     "exception": false,
     "start_time": "2021-07-31T11:00:12.898795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "num_bins = int(np.floor(1 + np.log2(len(df_train))))\n",
    "print(num_bins)\n",
    "df_train.loc[:,'bins'] = pd.cut(df_train['target'],bins=num_bins,labels=False)\n",
    "\n",
    "target = df_train['target'].to_numpy()\n",
    "bins = df_train.bins.to_numpy()\n",
    "\n",
    "def rmse_score(y_true,y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:13.013291Z",
     "iopub.status.busy": "2021-07-31T11:00:13.012811Z",
     "iopub.status.idle": "2021-07-31T11:00:13.016553Z",
     "shell.execute_reply": "2021-07-31T11:00:13.016127Z",
     "shell.execute_reply.started": "2021-07-31T10:27:58.441667Z"
    },
    "papermill": {
     "duration": 0.038946,
     "end_time": "2021-07-31T11:00:13.016657",
     "exception": false,
     "start_time": "2021-07-31T11:00:12.977711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_targets = df_train['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:13.086586Z",
     "iopub.status.busy": "2021-07-31T11:00:13.086014Z",
     "iopub.status.idle": "2021-07-31T11:00:13.093497Z",
     "shell.execute_reply": "2021-07-31T11:00:13.093042Z",
     "shell.execute_reply.started": "2021-07-31T10:28:01.617846Z"
    },
    "papermill": {
     "duration": 0.046657,
     "end_time": "2021-07-31T11:00:13.093613",
     "exception": false,
     "start_time": "2021-07-31T11:00:13.046956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size':128,\n",
    "    'max_len':256,\n",
    "    'nfolds':5,\n",
    "    'seed':42,\n",
    "}\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:13.160977Z",
     "iopub.status.busy": "2021-07-31T11:00:13.160366Z",
     "iopub.status.idle": "2021-07-31T11:00:13.164113Z",
     "shell.execute_reply": "2021-07-31T11:00:13.163637Z",
     "shell.execute_reply.started": "2021-07-31T10:28:05.717061Z"
    },
    "papermill": {
     "duration": 0.03891,
     "end_time": "2021-07-31T11:00:13.164232",
     "exception": false,
     "start_time": "2021-07-31T11:00:13.125322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLRPDataset(Dataset):\n",
    "    def __init__(self,df,tokenizer):\n",
    "        self.Text = df['Text'].to_numpy()\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.Text[idx],return_tensors='pt',\n",
    "                                max_length=config['max_len'],\n",
    "                                padding='max_length',truncation=True)\n",
    "        return encode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:13.237527Z",
     "iopub.status.busy": "2021-07-31T11:00:13.236343Z",
     "iopub.status.idle": "2021-07-31T11:00:13.238724Z",
     "shell.execute_reply": "2021-07-31T11:00:13.239119Z",
     "shell.execute_reply.started": "2021-07-31T10:28:10.007265Z"
    },
    "papermill": {
     "duration": 0.041184,
     "end_time": "2021-07-31T11:00:13.239239",
     "exception": false,
     "start_time": "2021-07-31T11:00:13.198055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, num_targets):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.middle_features = hidden_dim\n",
    "\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.W(features))\n",
    "\n",
    "        score = self.V(att)\n",
    "\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:13.309673Z",
     "iopub.status.busy": "2021-07-31T11:00:13.308092Z",
     "iopub.status.idle": "2021-07-31T11:00:13.310715Z",
     "shell.execute_reply": "2021-07-31T11:00:13.311183Z",
     "shell.execute_reply.started": "2021-07-31T10:28:13.640787Z"
    },
    "papermill": {
     "duration": 0.041729,
     "end_time": "2021-07-31T11:00:13.311311",
     "exception": false,
     "start_time": "2021-07-31T11:00:13.269582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n",
    "        self.head = AttentionHead(768,768,1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(self.head.out_features,1)\n",
    "\n",
    "    def forward(self,**xb):\n",
    "        x = self.roberta(**xb)[0]\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:13.382352Z",
     "iopub.status.busy": "2021-07-31T11:00:13.381128Z",
     "iopub.status.idle": "2021-07-31T11:00:13.383822Z",
     "shell.execute_reply": "2021-07-31T11:00:13.383425Z",
     "shell.execute_reply.started": "2021-07-31T10:28:16.474476Z"
    },
    "papermill": {
     "duration": 0.040496,
     "end_time": "2021-07-31T11:00:13.383924",
     "exception": false,
     "start_time": "2021-07-31T11:00:13.343428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(df,path,plot_losses=True, verbose=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"{device} is used\")\n",
    "            \n",
    "    model = Model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')\n",
    "    \n",
    "    ds = CLRPDataset(df,tokenizer)\n",
    "    dl = DataLoader(ds,\n",
    "                  batch_size = config[\"batch_size\"],\n",
    "                  shuffle=False,\n",
    "                  num_workers = 4,\n",
    "                  pin_memory=True,\n",
    "                  drop_last=False\n",
    "                 )\n",
    "        \n",
    "    embeddings = list()\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in tqdm(enumerate(dl)):\n",
    "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            embeddings.extend(outputs)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:00:13.497454Z",
     "iopub.status.busy": "2021-07-31T11:00:13.496891Z",
     "iopub.status.idle": "2021-07-31T11:03:03.882851Z",
     "shell.execute_reply": "2021-07-31T11:03:03.883551Z",
     "shell.execute_reply.started": "2021-07-31T10:28:20.352715Z"
    },
    "papermill": {
     "duration": 170.466922,
     "end_time": "2021-07-31T11:03:03.883797",
     "exception": false,
     "start_time": "2021-07-31T11:00:13.416875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "23it [00:22,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "1it [00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "1it [00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "1it [00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "23it [00:22,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "1it [00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "1it [00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings1 =  get_embeddings(df_train,'../input/clr-roberta/model0/model0.bin')\n",
    "test_embeddings1 = get_embeddings(df_test,'../input/clr-roberta/model0/model0.bin')\n",
    "\n",
    "train_embeddings2 =  get_embeddings(df_train,'../input/clr-roberta/model1/model1.bin')\n",
    "test_embeddings2 = get_embeddings(df_test,'../input/clr-roberta/model1/model1.bin')\n",
    "\n",
    "train_embeddings3 =  get_embeddings(df_train,'../input/clr-roberta/model2/model2.bin')\n",
    "test_embeddings3 = get_embeddings(df_test,'../input/clr-roberta/model2/model2.bin')\n",
    "\n",
    "train_embeddings4 =  get_embeddings(df_train,'../input/clr-roberta/model3/model3.bin')\n",
    "test_embeddings4 = get_embeddings(df_test,'../input/clr-roberta/model3/model3.bin')\n",
    "\n",
    "train_embeddings5 =  get_embeddings(df_train,'../input/clr-roberta/model4/model4.bin')\n",
    "test_embeddings5 = get_embeddings(df_test,'../input/clr-roberta/model4/model4.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:03:04.041867Z",
     "iopub.status.busy": "2021-07-31T11:03:04.041296Z",
     "iopub.status.idle": "2021-07-31T11:03:04.044988Z",
     "shell.execute_reply": "2021-07-31T11:03:04.044561Z",
     "shell.execute_reply.started": "2021-07-31T10:34:02.024231Z"
    },
    "papermill": {
     "duration": 0.086972,
     "end_time": "2021-07-31T11:03:04.045098",
     "exception": false,
     "start_time": "2021-07-31T11:03:03.958126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_data(train_embeddings, train_features, test_embeddings, test_features):\n",
    "    train_data = np.concatenate((train_embeddings,train_features.to_numpy()), axis=1)\n",
    "    test_data = np.concatenate((test_embeddings,test_features.to_numpy()), axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    train_data = scaler.fit_transform(train_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:03:04.203623Z",
     "iopub.status.busy": "2021-07-31T11:03:04.202622Z",
     "iopub.status.idle": "2021-07-31T11:03:04.362340Z",
     "shell.execute_reply": "2021-07-31T11:03:04.361861Z",
     "shell.execute_reply.started": "2021-07-31T10:34:05.550760Z"
    },
    "papermill": {
     "duration": 0.239968,
     "end_time": "2021-07-31T11:03:04.362460",
     "exception": false,
     "start_time": "2021-07-31T11:03:04.122492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data1, test_data1 = concat_data(train_embeddings1, train_features, test_embeddings1, test_features)\n",
    "train_data2, test_data2 = concat_data(train_embeddings2, train_features, test_embeddings2, test_features)\n",
    "train_data3, test_data3 = concat_data(train_embeddings3, train_features, test_embeddings3, test_features)\n",
    "train_data4, test_data4 = concat_data(train_embeddings4, train_features, test_embeddings4, test_features)\n",
    "train_data5, test_data5 = concat_data(train_embeddings5, train_features, test_embeddings5, test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.074987,
     "end_time": "2021-07-31T11:03:04.514941",
     "exception": false,
     "start_time": "2021-07-31T11:03:04.439954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:03:04.675261Z",
     "iopub.status.busy": "2021-07-31T11:03:04.674339Z",
     "iopub.status.idle": "2021-07-31T11:03:04.677331Z",
     "shell.execute_reply": "2021-07-31T11:03:04.676933Z",
     "shell.execute_reply.started": "2021-07-31T10:34:16.916039Z"
    },
    "papermill": {
     "duration": 0.088146,
     "end_time": "2021-07-31T11:03:04.677439",
     "exception": false,
     "start_time": "2021-07-31T11:03:04.589293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=1,kernel='rbf'):\n",
    "    scores = list()\n",
    "    preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
    "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
    "        model = SVR(C=C,kernel=kernel,gamma='auto')\n",
    "        X_train,y_train = X[train_idx], y[train_idx]\n",
    "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        prediction = model.predict(X_valid)\n",
    "        score = rmse_score(prediction,y_valid)\n",
    "        print(f'Fold {k} , rmse score: {score}')\n",
    "        scores.append(score)\n",
    "        preds += model.predict(X_test)\n",
    "        \n",
    "    print(\"mean rmse\",np.mean(scores))\n",
    "    return np.array(preds)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:03:04.834412Z",
     "iopub.status.busy": "2021-07-31T11:03:04.833609Z",
     "iopub.status.idle": "2021-07-31T11:05:34.464326Z",
     "shell.execute_reply": "2021-07-31T11:05:34.464999Z",
     "shell.execute_reply.started": "2021-07-31T10:34:20.683394Z"
    },
    "papermill": {
     "duration": 149.71112,
     "end_time": "2021-07-31T11:05:34.465269",
     "exception": false,
     "start_time": "2021-07-31T11:03:04.754149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 , rmse score: 0.475105521713043\n",
      "Fold 1 , rmse score: 0.2814163772050671\n",
      "Fold 2 , rmse score: 0.28066531135409917\n",
      "Fold 3 , rmse score: 0.26959251185277494\n",
      "Fold 4 , rmse score: 0.2809759899547531\n",
      "mean rmse 0.31755114241594745\n",
      "Fold 0 , rmse score: 0.2509852681743025\n",
      "Fold 1 , rmse score: 0.501382279324724\n",
      "Fold 2 , rmse score: 0.24856747354374117\n",
      "Fold 3 , rmse score: 0.24100000687770365\n",
      "Fold 4 , rmse score: 0.2499254345645391\n",
      "mean rmse 0.2983720924970021\n",
      "Fold 0 , rmse score: 0.387631166523031\n",
      "Fold 1 , rmse score: 0.41037792407406376\n",
      "Fold 2 , rmse score: 0.4950962177771016\n",
      "Fold 3 , rmse score: 0.3645208490806746\n",
      "Fold 4 , rmse score: 0.3833122394248934\n",
      "mean rmse 0.40818767937595285\n",
      "Fold 0 , rmse score: 0.29535446388767217\n",
      "Fold 1 , rmse score: 0.28628875452534563\n",
      "Fold 2 , rmse score: 0.2909706430542025\n",
      "Fold 3 , rmse score: 0.45483560724655364\n",
      "Fold 4 , rmse score: 0.2899225503298736\n",
      "mean rmse 0.3234744038087295\n",
      "Fold 0 , rmse score: 0.40074538690793726\n",
      "Fold 1 , rmse score: 0.4239944976419102\n",
      "Fold 2 , rmse score: 0.39559128394618176\n",
      "Fold 3 , rmse score: 0.3986983346003765\n",
      "Fold 4 , rmse score: 0.5075464554872008\n",
      "mean rmse 0.42531519171672133\n"
     ]
    }
   ],
   "source": [
    "svm_preds1 = get_preds_svm(train_data1,target,test_data1)\n",
    "svm_preds2 = get_preds_svm(train_data2,target,test_data2)\n",
    "svm_preds3 = get_preds_svm(train_data3,target,test_data3)\n",
    "svm_preds4 = get_preds_svm(train_data4,target,test_data4)\n",
    "svm_preds5 = get_preds_svm(train_data5,target,test_data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:05:34.624618Z",
     "iopub.status.busy": "2021-07-31T11:05:34.624113Z",
     "iopub.status.idle": "2021-07-31T11:05:34.627948Z",
     "shell.execute_reply": "2021-07-31T11:05:34.627533Z",
     "shell.execute_reply.started": "2021-07-31T10:37:50.161443Z"
    },
    "papermill": {
     "duration": 0.084732,
     "end_time": "2021-07-31T11:05:34.628058",
     "exception": false,
     "start_time": "2021-07-31T11:05:34.543326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:05:34.788587Z",
     "iopub.status.busy": "2021-07-31T11:05:34.788097Z",
     "iopub.status.idle": "2021-07-31T11:05:34.791827Z",
     "shell.execute_reply": "2021-07-31T11:05:34.791421Z",
     "shell.execute_reply.started": "2021-07-31T10:41:01.326807Z"
    },
    "papermill": {
     "duration": 0.086723,
     "end_time": "2021-07-31T11:05:34.791931",
     "exception": false,
     "start_time": "2021-07-31T11:05:34.705208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds_random_forest(X,y,X_test,bins=bins,nfolds=5):\n",
    "    scores = list()\n",
    "    preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
    "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
    "        model = RandomForestRegressor(n_estimators = 20, max_depth=4)\n",
    "        X_train,y_train = X[train_idx], y[train_idx]\n",
    "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        prediction = model.predict(X_valid)\n",
    "        score = rmse_score(prediction,y_valid)\n",
    "        print(f'Fold {k} , rmse score: {score}')\n",
    "        scores.append(score)\n",
    "        preds += model.predict(X_test)\n",
    "        \n",
    "    print(\"mean rmse\",np.mean(scores))\n",
    "    return np.array(preds)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:05:34.950166Z",
     "iopub.status.busy": "2021-07-31T11:05:34.949625Z",
     "iopub.status.idle": "2021-07-31T11:08:58.612858Z",
     "shell.execute_reply": "2021-07-31T11:08:58.612390Z",
     "shell.execute_reply.started": "2021-07-31T10:41:04.966884Z"
    },
    "papermill": {
     "duration": 203.744176,
     "end_time": "2021-07-31T11:08:58.612995",
     "exception": false,
     "start_time": "2021-07-31T11:05:34.868819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 , rmse score: 0.4867270658484281\n",
      "Fold 1 , rmse score: 0.31246027624311407\n",
      "Fold 2 , rmse score: 0.3159134277561694\n",
      "Fold 3 , rmse score: 0.2954668825123225\n",
      "Fold 4 , rmse score: 0.3074782426879434\n",
      "mean rmse 0.34360917900959553\n",
      "Fold 0 , rmse score: 0.29129574826326177\n",
      "Fold 1 , rmse score: 0.5318808836283744\n",
      "Fold 2 , rmse score: 0.2856377091522112\n",
      "Fold 3 , rmse score: 0.2845229604252749\n",
      "Fold 4 , rmse score: 0.2913696787897526\n",
      "mean rmse 0.336941396051775\n",
      "Fold 0 , rmse score: 0.4148810077674712\n",
      "Fold 1 , rmse score: 0.43771031708872427\n",
      "Fold 2 , rmse score: 0.5253526362198212\n",
      "Fold 3 , rmse score: 0.3966940814584421\n",
      "Fold 4 , rmse score: 0.40910013757965413\n",
      "mean rmse 0.43674763602282257\n",
      "Fold 0 , rmse score: 0.3323736002777699\n",
      "Fold 1 , rmse score: 0.33045178156127186\n",
      "Fold 2 , rmse score: 0.33180497461738484\n",
      "Fold 3 , rmse score: 0.47247894255046613\n",
      "Fold 4 , rmse score: 0.32949179581259375\n",
      "mean rmse 0.35932021896389726\n",
      "Fold 0 , rmse score: 0.4293431875424499\n",
      "Fold 1 , rmse score: 0.4491280217972067\n",
      "Fold 2 , rmse score: 0.430229159442412\n",
      "Fold 3 , rmse score: 0.423789547183289\n",
      "Fold 4 , rmse score: 0.5270642518927052\n",
      "mean rmse 0.45191083357161255\n"
     ]
    }
   ],
   "source": [
    "rf_preds1 = get_preds_random_forest(train_data1,target,test_data1)\n",
    "rf_preds2 = get_preds_random_forest(train_data2,target,test_data2)\n",
    "rf_preds3 = get_preds_random_forest(train_data3,target,test_data3)\n",
    "rf_preds4 = get_preds_random_forest(train_data4,target,test_data4)\n",
    "rf_preds5 = get_preds_random_forest(train_data5,target,test_data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:08:58.814426Z",
     "iopub.status.busy": "2021-07-31T11:08:58.813654Z",
     "iopub.status.idle": "2021-07-31T11:08:58.817053Z",
     "shell.execute_reply": "2021-07-31T11:08:58.816641Z",
     "shell.execute_reply.started": "2021-07-31T10:44:54.001350Z"
    },
    "papermill": {
     "duration": 0.097408,
     "end_time": "2021-07-31T11:08:58.817160",
     "exception": false,
     "start_time": "2021-07-31T11:08:58.719752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_preds = (rf_preds1 + rf_preds2 + rf_preds3 + rf_preds4 + rf_preds5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:08:59.005217Z",
     "iopub.status.busy": "2021-07-31T11:08:59.004466Z",
     "iopub.status.idle": "2021-07-31T11:08:59.006723Z",
     "shell.execute_reply": "2021-07-31T11:08:59.007126Z",
     "shell.execute_reply.started": "2021-07-31T10:44:59.535772Z"
    },
    "papermill": {
     "duration": 0.099463,
     "end_time": "2021-07-31T11:08:59.007243",
     "exception": false,
     "start_time": "2021-07-31T11:08:58.907780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds_adaboost(X,y,X_test,bins=bins,nfolds=5):\n",
    "    scores = list()\n",
    "    preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
    "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
    "        model = AdaBoostRegressor(n_estimators = 72)\n",
    "        X_train,y_train = X[train_idx], y[train_idx]\n",
    "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        prediction = model.predict(X_valid)\n",
    "        score = rmse_score(prediction,y_valid)\n",
    "        print(f'Fold {k} , rmse score: {score}')\n",
    "        scores.append(score)\n",
    "        preds += model.predict(X_test)\n",
    "        \n",
    "    print(\"mean rmse\",np.mean(scores))\n",
    "    return np.array(preds)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:08:59.193330Z",
     "iopub.status.busy": "2021-07-31T11:08:59.192407Z",
     "iopub.status.idle": "2021-07-31T11:18:18.488525Z",
     "shell.execute_reply": "2021-07-31T11:18:18.488977Z",
     "shell.execute_reply.started": "2021-07-31T10:45:02.444421Z"
    },
    "papermill": {
     "duration": 559.389436,
     "end_time": "2021-07-31T11:18:18.489151",
     "exception": false,
     "start_time": "2021-07-31T11:08:59.099715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 , rmse score: 0.4832599080339161\n",
      "Fold 1 , rmse score: 0.3126622620506336\n",
      "Fold 2 , rmse score: 0.3167980866278161\n",
      "Fold 3 , rmse score: 0.29523696739996375\n",
      "Fold 4 , rmse score: 0.31300414304427887\n",
      "mean rmse 0.3441922734313217\n",
      "Fold 0 , rmse score: 0.28953981808201656\n",
      "Fold 1 , rmse score: 0.516734221805008\n",
      "Fold 2 , rmse score: 0.2911677215046883\n",
      "Fold 3 , rmse score: 0.2805088888845369\n",
      "Fold 4 , rmse score: 0.3034286661633856\n",
      "mean rmse 0.3362758632879271\n",
      "Fold 0 , rmse score: 0.40853084897383546\n",
      "Fold 1 , rmse score: 0.42985831144473324\n",
      "Fold 2 , rmse score: 0.5066027327275975\n",
      "Fold 3 , rmse score: 0.3935285885831211\n",
      "Fold 4 , rmse score: 0.4056741148785237\n",
      "mean rmse 0.42883891932156215\n",
      "Fold 0 , rmse score: 0.32325396219320607\n",
      "Fold 1 , rmse score: 0.3212028542592625\n",
      "Fold 2 , rmse score: 0.31806155473060405\n",
      "Fold 3 , rmse score: 0.4633780582287487\n",
      "Fold 4 , rmse score: 0.3173333916302745\n",
      "mean rmse 0.34864596420841915\n",
      "Fold 0 , rmse score: 0.42633565287376685\n",
      "Fold 1 , rmse score: 0.44785623204319036\n",
      "Fold 2 , rmse score: 0.4147594938184176\n",
      "Fold 3 , rmse score: 0.41801451465066436\n",
      "Fold 4 , rmse score: 0.5275458752081974\n",
      "mean rmse 0.44690235371884734\n"
     ]
    }
   ],
   "source": [
    "adb_preds1 = get_preds_adaboost(train_data1,target,test_data1)\n",
    "adb_preds2 = get_preds_adaboost(train_data2,target,test_data2)\n",
    "adb_preds3 = get_preds_adaboost(train_data3,target,test_data3)\n",
    "adb_preds4 = get_preds_adaboost(train_data4,target,test_data4)\n",
    "adb_preds5 = get_preds_adaboost(train_data5,target,test_data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:18:18.681423Z",
     "iopub.status.busy": "2021-07-31T11:18:18.680911Z",
     "iopub.status.idle": "2021-07-31T11:18:18.684813Z",
     "shell.execute_reply": "2021-07-31T11:18:18.684365Z",
     "shell.execute_reply.started": "2021-07-31T10:55:11.751828Z"
    },
    "papermill": {
     "duration": 0.105454,
     "end_time": "2021-07-31T11:18:18.684925",
     "exception": false,
     "start_time": "2021-07-31T11:18:18.579471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adb_preds = (adb_preds1 + adb_preds2 + adb_preds3 + adb_preds4 + adb_preds5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:18:18.871993Z",
     "iopub.status.busy": "2021-07-31T11:18:18.871399Z",
     "iopub.status.idle": "2021-07-31T11:18:18.877499Z",
     "shell.execute_reply": "2021-07-31T11:18:18.877114Z",
     "shell.execute_reply.started": "2021-07-31T10:55:15.777056Z"
    },
    "papermill": {
     "duration": 0.099634,
     "end_time": "2021-07-31T11:18:18.877600",
     "exception": false,
     "start_time": "2021-07-31T11:18:18.777966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.target = (svm_preds+rf_preds+adb_preds)/3\n",
    "sample.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T11:18:19.061424Z",
     "iopub.status.busy": "2021-07-31T11:18:19.060785Z",
     "iopub.status.idle": "2021-07-31T11:18:19.074766Z",
     "shell.execute_reply": "2021-07-31T11:18:19.074329Z",
     "shell.execute_reply.started": "2021-07-31T10:55:18.832192Z"
    },
    "papermill": {
     "duration": 0.108273,
     "end_time": "2021-07-31T11:18:19.074868",
     "exception": false,
     "start_time": "2021-07-31T11:18:18.966595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.434773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.648937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.491356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.453608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.766856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-1.360294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.278843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.434773\n",
       "1  f0953f0a5 -0.648937\n",
       "2  0df072751 -0.491356\n",
       "3  04caf4e0c -2.453608\n",
       "4  0e63f8bea -1.766856\n",
       "5  12537fe78 -1.360294\n",
       "6  965e592c0  0.278843"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.08903,
     "end_time": "2021-07-31T11:18:19.254166",
     "exception": false,
     "start_time": "2021-07-31T11:18:19.165136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1352.027217,
   "end_time": "2021-07-31T11:18:23.023383",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-31T10:55:50.996166",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
